{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "<h1><center>A Speech Analysis</center></h1>\n========================\n\n## <center>Purpose</center>\n\n<font style=courier>It is amazing how little attention is paid to the language that we use on a daily basis. Language is second nature to us, and as a result, it fades into the background of our minds. We forget in every sentence and syllable just how powerful this tool is which we wield. Though, at times, this can be a strength.</font>\n    \nIf we take the effort to unpack and examine any unconscious human process, we gain the power to learn a vast amount about ourselves."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Key to the .person attribute\npeople = {\n    1 : 'Joe Biden',\n    2 : 'Donald Trump',\n    3 : 'Bernie Sanders'\n}\n\nfrom stripper import *\ntest = VIP('test.xlsx')\n\nbiden = test[test['person'] == 1]\ntrump = test[test['person'] == 2]\nsanders = test[test['person'] == 3]\n\nbiden_selfish = biden[['loc avg humor young','loc avg humor old']]\ntrump_selfish = trump[['loc avg humor young','loc avg humor old']]\nsanders_selfish = sanders[['loc avg humor young','loc avg humor old']]\n\nprint('Biden: ', biden_selfish.mean(), 'Trump: ', trump_selfish.mean(), 'Sanders: ', sanders_selfish.mean())",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Biden:  loc avg humor young    2.076667\nloc avg humor old      2.141398\ndtype: float64 Trump:  loc avg humor young    2.045351\nloc avg humor old      2.187287\ndtype: float64 Sanders:  loc avg humor young    2.176682\nloc avg humor old      2.260853\ndtype: float64\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "insp = VIP('test.xlsx', xxx=1)\n# print(insp[24].sents)\n# print()\n# print(insp[24].selfish)\nfor i in range(len(insp)):\n    selfcount = len([word for word in insp[i].clean_words if word in selfish])\n    wrd_snt = insp[i].wordcount / len(insp[i].sents)\n    bysent = selfcount / len(insp[i].sents)\n    print(bysent)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1.3571428571428572\n0.2692307692307692\n0.6363636363636364\n0.8\n0.25\n0.38961038961038963\n0.47368421052631576\n0.5686274509803921\n0.5555555555555556\n0.41975308641975306\n0.3142857142857143\n0.625\n0.08333333333333333\n0.7857142857142857\n0.9090909090909091\n0.6\n0.36\n1.3333333333333333\n1.2\n0.45454545454545453\n0.0\n0.8888888888888888\n0.35\n0.3333333333333333\n1.0\n0.208955223880597\n0.5263157894736842\n2.0\n0.4\n1.125\n0.6666666666666666\n1.3333333333333333\n0.875\n0.16666666666666666\n2.0\n2.5\n0.5454545454545454\n0.75\n0.14285714285714285\n0.3333333333333333\n1.0\n0.375\n0.6\n0.47058823529411764\n0.8571428571428571\n0.8\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "dir(insp[24])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "['__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__gt__',\n '__hash__',\n '__init__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n 'adj',\n 'adv',\n 'ag_anger',\n 'ag_anticipation',\n 'ag_arousal',\n 'ag_disgust',\n 'ag_dominance',\n 'ag_fear',\n 'ag_humor_F',\n 'ag_humor_M',\n 'ag_humor_old',\n 'ag_humor_tot',\n 'ag_humor_young',\n 'ag_joy',\n 'ag_sadness',\n 'ag_surprise',\n 'ag_trust',\n 'ag_valence',\n 'age',\n 'al_anger',\n 'al_anticipation',\n 'al_arousal',\n 'al_disgust',\n 'al_dominance',\n 'al_fear',\n 'al_humor_F',\n 'al_humor_M',\n 'al_humor_old',\n 'al_humor_tot',\n 'al_humor_young',\n 'al_joy',\n 'al_sadness',\n 'al_surprise',\n 'al_trust',\n 'al_valence',\n 'anger',\n 'anticipation',\n 'arousal',\n 'bare',\n 'clean_words',\n 'conj',\n 'counts',\n 'date',\n 'diagnosis',\n 'disgust',\n 'dominance',\n 'fear',\n 'frag',\n 'freq',\n 'funcs_freq',\n 'gender',\n 'humor',\n 'index',\n 'intj',\n 'joy',\n 'long_sent',\n 'long_word',\n 'noun',\n 'num_sents',\n 'person',\n 'pos',\n 'pos_sents',\n 'prep',\n 'pron',\n 'rare',\n 'rare_nonfunc',\n 'sadness',\n 'selfish',\n 'sent_counts',\n 'sents',\n 'short_sent',\n 'short_word',\n 'stripped',\n 'surprise',\n 'time',\n 'trust',\n 'unique_words',\n 'valence',\n 'verb',\n 'wh',\n 'wordcount',\n 'words_raw',\n 'words_tok']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "check = [test[0].freq[word] for word in test[0].freq if word in selfish]\nprint(check)\nratio = sum(check) / test[0].wordcount\nprint(ratio)\nans = ratio *100\nprint(ans)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[2, 3]\n0.045871559633027525\n4.587155963302752\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "selfish = {'I', 'me', 'my', 'myself', 'mine', \"I’ll\", \"I'll\", \"I'll\", \"I’m\", \"i’ll\", \"i’m\", \"i’ve\", \"i’d\", \"i’d’ve\", 'i', \"i’ll\", \"i’m\", \"i’ve\", \"i’d\", \"i’d’ve\", 'i', \"i’ll\", \"i’m\", \"i’ve\", \"i’d\", \"i’d’ve\", 'i'}\nselfish = list(selfish)\nselfish = ['I’m',\n \"i'll\",\n 'i’ll',\n 'me',\n 'I’ll',\n 'i’d', \"i'd\",\n 'my',\n 'myself',\n 'i’m', \"i'm\",\n 'i’ve', \"i've\",\n 'I',\n 'i’d’ve', \"i'd've\",\n 'i',\n 'mine']\nselfish",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "['I’m',\n \"i'll\",\n 'i’ll',\n 'me',\n 'I’ll',\n 'i’d',\n \"i'd\",\n 'my',\n 'myself',\n 'i’m',\n \"i'm\",\n 'i’ve',\n \"i've\",\n 'I',\n 'i’d’ve',\n \"i'd've\",\n 'i',\n 'mine']"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}